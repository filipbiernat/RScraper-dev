name: RScraper

on:
  workflow_dispatch:  # This enables manual trigger of the workflow
  schedule:
    - cron: '0 3 * * *' # Run daily at 4:00 AM CET, 3:00 AM UTC
      

jobs:
  scrape:
    runs-on: ubuntu-latest  # You can also choose windows-latest if you prefer to run on Windows

    steps:
    # Steps to perform in the job

    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v2

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'  # Or another version of Python that you use

    # Step 3: Install python dependencies (e.g., selenium)
    - name: Install python dependencies
      run: |
        pip install -r requirements.txt

    # Step 4: Install chromedriver
    - name: Install chromedriver
      run: |
        sudo apt-get install -y chromium-chromedriver  # Install chromedriver on Ubuntu

    # Step 4a: Check chromedriver
    - name: Check chromedriver 1 
      run: |
        dpkg -l | grep chromium-chromedriver


    # Step 4a: Check chromedriver
    - name: Check chromedriver 3
      run: |
        whereis chromium-chromedriver

    # Step 5: Run the scraper script
    - name: Run scraper
      run: |
        python RScraper.py
