name: RScraper

on:
  workflow_dispatch:  # This enables manual trigger of the workflow
  schedule:
    - cron: '0 3 * * *' # Run daily at 3:00 AM UTC
      

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    # Steps to perform in the job

    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v2

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'  # Or another version of Python that you use

    # Step 3: Install python dependencies
    - name: Install python dependencies
      run: |
        pip install selenium

    # Step 4: Install Chromium for Ubuntu
    - name: Install Chromium
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser

    # Step 5: Install chromedriver  for Ubuntu
    - name: Install chromedriver
      run: |
        sudo apt-get install -y chromium-chromedriver

    # Step 6: Run the scraper script
    - name: Run scraper
      run: |
        python RScraper/RScraper.py

    # Step 7: Check if 'data' folder exists and commit all files if it is not empty
    - name: Check if 'data' folder exists and commit all files
      if: always()  # This ensures the step will run no matter what
      run: |
        if [ -d "data" ] && [ "$(ls -A data)" ]; then
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          TIMESTAMP=$(date +"%d.%m.%Y %H:%M:%S")  # Format DD.MM.RRRR HH:MM:SS
          git add data/*
          git commit -m "Auto-update: Data from $TIMESTAMP ðŸ•’"
          git push
        else
          echo "Data folder is either empty or does not exist, skipping commit."
        fi