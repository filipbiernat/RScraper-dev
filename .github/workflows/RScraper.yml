name: RScraper

on:
  workflow_dispatch:  # This enables manual trigger of the workflow
  schedule:
    - cron: '0 3 * * *' # Run daily at 4:00 AM CET, 3:00 AM UTC
      

jobs:
  scrape:
    runs-on: ubuntu-latest  # You can also choose windows-latest if you prefer to run on Windows

    steps:
    # Steps to perform in the job

    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v2

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'  # Or another version of Python that you use

    # Step 3: Install python dependencies (e.g., selenium)
    - name: Install python dependencies
      run: |
        pip install -r requirements.txt

    # Step 4: Install Chromium
    - name: Install Chromium
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser

    # Step 4b: Verify Chromium
    - name: Verify Chromium installation 1
      run: |
        chromium-browser --version

    # Step 4b: Verify Chromium
    - name: Verify Chromium installation 2
      run: |
        whereis google-chrome

    # Step 4b: Verify Chromium
    - name: Verify Chromium installation 3
      run: |
        which google-chrome

    # Step 5: Install chromedriver
    - name: Install chromedriver
      run: |
        sudo apt-get install -y chromium-chromedriver  # Install chromedriver on Ubuntu

    # Step 6: Run the scraper script
    - name: Run scraper
      run: |
        python RScraper.py
