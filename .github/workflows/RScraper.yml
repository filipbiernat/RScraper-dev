name: RScraper

on:
  workflow_dispatch:  # This enables manual trigger of the workflow
  schedule:
    - cron: '0 3 * * *' # Run daily at 4:00 AM CET, 3:00 AM UTC
      

jobs:
  scrape:
    runs-on: ubuntu-latest  # You can also choose windows-latest if you prefer to run on Windows

    steps:
    # Steps to perform in the job

    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v2

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'  # Or another version of Python that you use

    # Step 3: Install python dependencies (e.g., selenium)
    - name: Install python dependencies
      run: |
        pip install -r requirements.txt

    # Step 4: Install Chromium
    - name: Install Chromium
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser

    # Step 4b: Verify Chromium
    - name: Verify Chromium installation 1
      run: |
        chromium-browser --version

    # Step 4b: Verify Chromium
    - name: Verify Chromium installation 2
      run: |
        whereis chromium-browser 

    # Step 4b: Verify Chromium
    - name: Verify Chromium installation 3
      run: |
        which chromium-browser 

    # Step 5: Install chromedriver
    - name: Install chromedriver
      run: |
        sudo apt-get install -y chromium-chromedriver  # Install chromedriver on Ubuntu

    # Step 6: Run the scraper script
    - name: Run scraper
      run: |
        python RScraper.py

    # Step 7: Check if page_source.html exists and commit it if it does
    - name: Check if page_source.html exists and commit
      continue-on-error: true  # Ensure this step runs even if previous steps failed
      run: |
        if [ -f "page_source.html" ]; then
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          git add page_source.html
          git commit -m "Add page_source.html from scraper"
          git push
        else
          echo "No page_source.html found, skipping commit."
        fi